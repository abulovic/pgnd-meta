{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,) int32\n",
      "[ 0 10 20 30 40 50 60 70 80 90] \n",
      "\n",
      "/ <class 'h5py._hl.files.File'> \n",
      "\n",
      "/mydataset <class 'h5py._hl.dataset.Dataset'> \n",
      "\n",
      "/subgroup <class 'h5py._hl.group.Group'> \n",
      "\n",
      "/subgroup/another_dataset <class 'h5py._hl.dataset.Dataset'> \n",
      "\n",
      "/subgroup2/dataset_three <class 'h5py._hl.dataset.Dataset'> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"mytestfile.hdf5\", \"w\") as f:\n",
    "    dset = f.create_dataset(\"mydataset\", (100,), dtype='i')\n",
    "    print dset.shape, dset.dtype\n",
    "    dset[...] = np.arange(100)\n",
    "    print dset[0:100:10], '\\n'\n",
    "    print f.name, type(f), '\\n'\n",
    "    print dset.name, type(dset), '\\n'\n",
    "    grp = f.create_group(\"subgroup\")\n",
    "    print grp.name, type(grp), '\\n'\n",
    "    dset2 = grp.create_dataset(\"another_dataset\", (50,), dtype='f')\n",
    "    print dset2.name, type(dset2), '\\n'\n",
    "    dset3 = f.create_dataset('subgroup2/dataset_three', (10,), dtype='i')\n",
    "    print dset3.name, type(dset3), '\\n'\n",
    "    # Attributes of the dataset\n",
    "    dset.attrs['temperature'] = 99.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# h5py with pandas\n",
    "from pandas import HDFStore, DataFrame\n",
    "\n",
    "with HDFStore('storage.h5') as hdf:\n",
    "    df = DataFrame(np.random.rand(5,3), columns=('A','B','C'))\n",
    "    hdf.put('d1', df, format='table', data_columns=True)\n",
    "    print hdf['d1'].shape\n",
    "    hdf.append('d1', DataFrame(np.random.rand(5,3), columns=('A','B','C')), \n",
    "               format='table', data_columns=True)\n",
    "    print type(hdf['d1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B\n",
      "2  0.537706  0.771100\n",
      "3  0.926372  0.729073\n",
      "1  0.587668  0.034781\n",
      "3  0.621757  0.624549\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_hdf\n",
    "\n",
    "hdf = read_hdf('storage.h5', 'd1', where='A>.5', columns=('A', 'B'))\n",
    "print hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.io.pytables.HDFStore'>\n",
      "File path: storage.h5\n",
      "/d1                       frame_table  (typ->appendable,nrows->10,ncols->3,indexers->[index],dc->[A,B,C])\n",
      "/new_tables/t1            frame        (shape->[15,2])                                                   \n",
      "/tables/t1                frame        (shape->[20,5])                                                   \n",
      "/tables/t2                frame        (shape->[10,3])                                                   \n"
     ]
    }
   ],
   "source": [
    "with HDFStore('storage.h5') as hdf:\n",
    "    hdf.put('tables/t1', DataFrame(np.random.rand(20, 5)))\n",
    "    hdf.put('tables/t2', DataFrame(np.random.rand(10,3)))\n",
    "    hdf.put('new_tables/t1', DataFrame(np.random.rand(15,2)))\n",
    "    print hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root:  / (RootGroup) u''\n",
      "objecttree.h5 (File) u''\n",
      "Last modif.: 'Fri May 27 13:54:07 2016'\n",
      "Object Tree: \n",
      "/ (RootGroup) u''\n",
      "/array1 (Array(2,)) 'String array'\n",
      "/group1 (Group) u''\n",
      "/group1/array2 (Array(4,)) ''\n",
      "/group1/table1 (Table(0,)) ''\n",
      "/group2 (Group) u''\n",
      "/group2/table2 (Table(0,)) ''\n",
      "\n",
      "objecttree.h5 (File) u''\n",
      "Last modif.: 'Fri May 27 13:54:07 2016'\n",
      "Object Tree: \n",
      "/ (RootGroup) u''\n",
      "/array1 (Array(2,)) 'String array'\n",
      "/group1 (Group) u''\n",
      "/group1/array2 (Array(4,)) ''\n",
      "/group1/table1 (Table(10,)) ''\n",
      "/group2 (Group) u''\n",
      "/group2/table2 (Table(10,)) ''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tables import *\n",
    "\n",
    "class Particle(IsDescription):\n",
    "    identity = StringCol(itemsize=22, dflt=\" \", pos=0)  # character String\n",
    "    idnumber = Int16Col(dflt=1, pos = 1)  # short integer\n",
    "    speed    = Float32Col(dflt=1, pos = 2)  # single-precision\n",
    "\n",
    "fileh = open_file('objecttree.h5', mode='w')\n",
    "\n",
    "root = fileh.root\n",
    "print 'Root: ', root\n",
    "\n",
    "group1 = fileh.create_group(root, \"group1\")\n",
    "group2 = fileh.create_group(root, \"group2\")\n",
    "\n",
    "array1 = fileh.create_array(root, \"array1\", [\"string\", \"array\"], \"String array\")\n",
    "\n",
    "table1 = fileh.create_table(group1, \"table1\", Particle)\n",
    "table2 = fileh.create_table(\"/group2\", \"table2\", Particle)\n",
    "array2 = fileh.create_array(\"/group1\", \"array2\", [1,2,3,4])\n",
    "\n",
    "print fileh\n",
    "\n",
    "# Now, fill the tables\n",
    "for table in (table1, table2):\n",
    "    # Get the record object associated with the table:\n",
    "    row = table.row\n",
    "\n",
    "    # Fill the table with 10 records\n",
    "    for i in xrange(10):\n",
    "        # First, assign the values to the Particle record\n",
    "        row['identity']  = 'This is particle: %2d' % (i)\n",
    "        row['idnumber'] = i\n",
    "        row['speed']  = i * 2.\n",
    "\n",
    "        # This injects the Record values\n",
    "        row.append()\n",
    "\n",
    "    # Flush the table buffers\n",
    "    table.flush()\n",
    "    \n",
    "print fileh\n",
    "\n",
    "fileh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
